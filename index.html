<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">

  <title>MTP: A Dataset for Multi-Modal Turning Points in Casual Conversations</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <style>
    /* Reset link color */
    a {
        color: inherit; /* Inherit color from parent */
        text-decoration: none; /* Remove underline */
    }

    .author-block a.monash {
    color: #f68946 !important; /* VinUniversity color */
    font-weight: normal;
    }

    .author-block a.vinuni {
        color: #008AD7 !important; /* Monash color */
        font-weight: normal;
    }

    .author-block a.default {
        color: #008AD7;
        font-weight: normal;
    }
    
</style>
</head>



<body>
  <section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">üîç MTP: <span class="is-size-2"><span class="is-size-1">M</span>ulti-<span class="is-size-1">M</span>odal <span class="is-size-1">T</span>urning <span class="is-size-1">P</span>oints</span></h1>
                    <h3 class="title is-3 publication-title">A Dataset for Multi-Modal Turning Points in Casual Conversations</h3>
                    <h5 class="subtitle is-5 publication-title" style="color: red; font-weight: bold;">ACL 2024 (main)</h5>


                    <div class="is-size-5 publication-authors">
                      <span class="author-block">
                        <a href="https://github.com/giaabaoo" class="vinuni">Gia-Bao Dinh Ho</a>,
                      </span>
                      <span class="author-block">
                          <a href="https://changweitan.com/" class="monash">Chang Wei Tan</a>,
                      </span>
                      <span class="author-block">
                          <a href="https://www.linkedin.com/in/zahra-zamanzadeh" class="monash">Zahra Zamanzadeh Darban</a>,
                      </span>
                      <span class="author-block">
                          <a href="https://sites.google.com/monash.edu/mahsasalehi/home" class="monash">Mahsa Salehi</a>,
                      </span>
                      <span class="author-block">
                          <a href="https://users.monash.edu.au/~gholamrh/" class="monash">Gholamreza Haffari</a>,
                      </span>
                      <span class="author-block">
                          <a href="https://bayesian-models.org/" class="vinuni">Wray Buntine</a>
                      </span>
                    </div>

                    <div class="is-size-5 publication-authors">
                        <span class="author-block"><b style="color: #f68946; font-weight: normal;">&#x25B6; </b> Monash University</span>
                        <span class="author-block"><b style="color: #008AD7; font-weight: normal;">&#x25B6; </b> VinUniversity</span>
                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <span class="link-block">
                                <a href="https://aclanthology.org/2024.acl-short.30.pdf" target="_blank" class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="ai ai-arxiv"></i>
                                    </span>
                                    <span>Paper</span>
                                </a>
                            </span>
                            <span class="link-block">
                                <a href="https://github.com/giaabaoo/MTP_pipeline" target="_blank" class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="fab fa-github"></i>
                                    </span>
                                    <span>Code</span>
                                </a>
                            </span>
                            <span class="link-block">
                                <a href="https://drive.google.com/file/d/1K8GUORTLHO-s7PNJHtHQ0RWHo1GaCye7/view?usp=sharing" target="_blank" class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="far fa-images"></i>
                                    </span>
                                    <span>Poster</span>
                                </a>
                            </span>
                            <span class="link-block">
                                <a href="https://drive.google.com/drive/folders/1xz0RwB9WmUCXSMr4SHhH5GvaNQ78IqA4?usp=drive_link" target="_blank" class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="fas fa-database"></i>
                                    </span>
                                    <span>Dataset</span>
                                </a>
                            </span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

  

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/demo.png" alt="" style="width: 100%; height: auto;">
      <h2 class="subtitle has-text-centered">
         A turning point in a casual conversation between a woman and two men
      </h2>
    </div>
  </div>
</section>


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Detecting critical moments, such as emotional outbursts or changes in decisions during conversations, is crucial for understanding shifts in human behavior and their consequences. Our work introduces a novel problem setting that focuses on these moments as "turning points (TPs)," accompanied by a meticulously curated, high-consensus, human-annotated multi-modal dataset. We provide precise timestamps, descriptions, and visual-textual evidence highlighting changes in emotions, behaviors, perspectives, and decisions at these turning points. Additionally, we propose a framework, TPMaven, which utilizes state-of-the-art vision-language models to construct a narrative from the videos and large language models. Evaluation results show that TPMaven achieves an F1-score of 0.88 in classification and 0.61 in detection, with additional explanations aligning with human expectations.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->





<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <img src="static/images/demo.png" alt="MY ALT TEXT"/>
          <h2 class="subtitle has-text-centered">
            Emotional outbursts significantly change other speakers' states
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- End image carousel -->


<section class="hero teaser"></section>
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/formulation.png" alt="" style="width: 100%; height: auto;">
    </div>
  </div>
</section>



<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title">Sample Conversations</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="video-container">
          <video id="video1" autoplay controls muted loop style="width: 100%;">
            <source src="static/videos/conversation_1_small.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
        <div class="video-container">
          <video id="video2" autoplay controls muted loop style="width: 100%;">
            <source src="static/videos/conversation_4_small.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="DownloadLinks">
  <div class="container is-max-desktop content">
    <h2 class="title">Dataset Usage</h2>
    <p>
      <u>
          <a href="https://drive.google.com/file/d/1sHigqVVqr8h5X_wxA2m8sGUB7vvKWxBS/view?usp=sharing" class="default">Here</a>
      </u> 
      is the Data Usage Agreement. Please sign it and send the signed document back to this email: 
      dinhhogiabao@gmail.com with the subject title: "Request Access for the MTP Dataset." We will send the full dataset link to your email upon receiving the signed document.
  </p>
  <p>
    The full dataset comprising 340 conversations, totaling approximately 13.3 hours of video content. The dataset will include additional utterance-level videos, transcripts, speaker IDs, and annotation files for turning points. Currently, we have provided some sample files 
    <u>
        <a href="https://drive.google.com/drive/folders/1Su1dbNCdCu6U28C92q7-0EoyoPnBNsbx?usp=drive_link">in this link</a>
    </u> 
    to enhance the reviewing process.
</p>

  </div>
</section>


<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{bigbangtheory,
      title={The Big Bang Theory},
      author={Chuck Lorre and Bill Prady},
      year={2007},
      journal={CBS},
      url={https://www.cbs.com/shows/big_bang_theory/}}
    </code></pre>

    <pre><code>@inproceedings{ho-etal-2024-mtp,
      title = "{MTP}: A Dataset for Multi-Modal Turning Points in Casual Conversations",
      author = "Ho, Gia-Bao  and Tan, Chang  and Darban, Zahra  and Salehi, Mahsa  and Haf, Reza  and Buntine, Wray",
      editor = "Ku, Lun-Wei and Martins, Andre  and Srikumar, Vivek",
      booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
      month = aug,
      year = "2024",
      address = "Bangkok, Thailand",
      publisher = "Association for Computational Linguistics",
      url = "https://aclanthology.org/2024.acl-short.30",
      pages = "314--326",
      abstract = "Detecting critical moments, such as emotional outbursts or changes in decisions during conversations, is crucial for understanding shifts in human behavior and their consequences. Our work introduces a novel problem setting focusing on these moments as turning points (TPs), accompanied by a meticulously curated, high-consensus, human-annotated multi-modal dataset. We provide precise timestamps, descriptions, and visual-textual evidence high-lighting changes in emotions, behaviors, perspectives, and decisions at these turning points. We also propose a framework, TPMaven, utilizing state-of-the-art vision-language models to construct a narrative from the videos and large language models to classify and detect turning points in our multi-modal dataset. Evaluation results show that TPMaven achieves an F1-score of 0.88 in classification and 0.61 in detection, with additional explanations aligning with human expectations.",
    }
    </code></pre>
  </div>
</section>

<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the¬†<a href="https://nerfies.github.io" target="_blank">Nerfies</a>¬†project page.
            You are free to borrow the source of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>



  </body>
  </html>
